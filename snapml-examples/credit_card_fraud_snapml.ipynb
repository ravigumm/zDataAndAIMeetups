{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2022 IBM Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest on Credit Card Fraud Dataset\n",
    "\n",
    "## Background \n",
    "\n",
    "The goal of this competition is to predict if a credit card transaction is fraudulent or genuine based on a set of anonymized features.\n",
    "\n",
    "## Source\n",
    "\n",
    "The raw dataset was obtained from [Kaggle: Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goals of this notebook are to illustrate how to use Snap ML to: 1) import a scikit-learn random forest trained on this dataset into Snap ML, and 2) run inference on the Z AI accelerator using the Snap ML prediction engine.\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:12.291870Z",
     "iopub.status.busy": "2022-04-04T14:47:12.291527Z",
     "iopub.status.idle": "2022-04-04T14:47:12.292514Z",
     "shell.execute_reply": "2022-04-04T14:47:12.292801Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is the directory where the dataset is stored\n",
    "# For this meetup, dataset is already present in the cache directory\n",
    "CACHE_DIR='cache-dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:12.295411Z",
     "iopub.status.busy": "2022-04-04T14:47:12.295051Z",
     "iopub.status.idle": "2022-04-04T14:47:12.963739Z",
     "shell.execute_reply": "2022-04-04T14:47:12.964031Z"
    }
   },
   "outputs": [],
   "source": [
    "# The numpy library helps us to have highly efficient arrays for manipulating the dataset\n",
    "# Please refer https://numpy.org/doc/stable/user/absolute_beginners.html\n",
    "import numpy as np\n",
    "\n",
    "# For calculating performance of sklearn and Snap ML frameworks\n",
    "import time\n",
    "\n",
    "# datasets module loads and pre-processes the dataset\n",
    "# It can also download the dataset from Kaggle if necessary (but we won't be using that feature for now)\n",
    "from datasets import CreditCardFraud\n",
    "\n",
    "# The metrics module of sklearn allows us to measure the accuracy of our models\n",
    "from sklearn.metrics import balanced_accuracy_score as score\n",
    "\n",
    "# sklearn2pmml library Allows us to export an sklearn model in PMML format\n",
    "# Please refer https://github.com/jpmml/sklearn2pmml\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "\n",
    "# Allows us to build an sklearn pipeline which can be used for exporting the model\n",
    "# A pipeline allows us to automate a number of steps required for creating a model\n",
    "# Please refer https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "from sklearn2pmml import PMMLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use the Random Foreset Classifier for training the model, this is the sklearn's version\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the Snap ML's version of Random Forest Classifier\n",
    "from snapml import RandomForestClassifier as SnapRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:12.967787Z",
     "iopub.status.busy": "2022-04-04T14:47:12.967420Z",
     "iopub.status.idle": "2022-04-04T14:47:12.994671Z",
     "shell.execute_reply": "2022-04-04T14:47:12.994955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset from cache directory\n",
    "dataset = CreditCardFraud(cache_dir=CACHE_DIR)\n",
    "\n",
    "# Here, we use the helper functions from dataset module to split the dataset for training and testing\n",
    "# The X_train and X_test contains features for training and testing\n",
    "# The y_train and y_test contains the target values, in this case fraud/non-fraudulent\n",
    "# Please see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test = dataset.get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:12.998107Z",
     "iopub.status.busy": "2022-04-04T14:47:12.997755Z",
     "iopub.status.idle": "2022-04-04T14:47:13.003876Z",
     "shell.execute_reply": "2022-04-04T14:47:13.004181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show the number of examples, features and the classes the dataset have\n",
    "print(\"Number of examples: %d\" % (X_train.shape[0]))\n",
    "print(\"Number of features: %d\" % (X_train.shape[1]))\n",
    "print(\"Number of classes:  %d\" % (len(np.unique(y_train))))\n",
    "print(\"Classes:  \", (np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:13.050484Z",
     "iopub.status.busy": "2022-04-04T14:47:13.048445Z",
     "iopub.status.idle": "2022-04-04T14:47:27.369502Z",
     "shell.execute_reply": "2022-04-04T14:47:27.369797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a scikit-learn Random Forest Classifier model\n",
    "# It uses a number of decision trees then uses the average of their outputs for prediction\n",
    "# n_estimators is the number of trees in the forest\n",
    "# max_depth is the maximum depth of individual trees\n",
    "# n_jobs is the number of jobs to be run in parallel\n",
    "# random_state argument allows us to pass a number to sklearn to seed the random number generator\n",
    "# Please refer https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "model = RandomForestClassifier(n_estimators = 200, max_depth=6, n_jobs=4, random_state=42)\n",
    "\n",
    "# Train a PMML pipeline that uses the scikit-learn model defined above\n",
    "pipeline = PMMLPipeline([(\"model\", model)]).fit(X_train, y_train)\n",
    "\n",
    "# Export the trained PMML pipeline, which includes the model to the file \"model.pmml\"\n",
    "sklearn2pmml(pipeline, \"model.pmml\", with_repr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of dataset to be used for testing\n",
    "test_data_size = 128\n",
    "\n",
    "# List of time taken for each inference\n",
    "inference_time_list = []\n",
    "\n",
    "# List of inference scores\n",
    "score_list = []\n",
    "\n",
    "# Seed the random number generator of numpy\n",
    "# This allows numpy to randomly select data from the dataset\n",
    "np.random.seed(1000)\n",
    "\n",
    "# inferences are done 100 times, each on a batch of `test_data_size` number of transactions\n",
    "for batch_index in range(100):\n",
    "    # Retrieve indices of `test_data_size` number of transactions randomly from the test dataset\n",
    "    test_data_indices = np.random.choice(X_test.shape[0], test_data_size)\n",
    "    \n",
    "    # Get the current time\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Do inferences on the `test_data_size` number of transactions\n",
    "    preds = pipeline.predict(X_test[test_data_indices])\n",
    "    \n",
    "    # Calculate the time taken to perform the inference\n",
    "    t_predict_sklearn = time.time() - t0\n",
    "    \n",
    "    # Store the time taken for the inference\n",
    "    inference_time_list.append(t_predict_sklearn)\n",
    "    \n",
    "    # Calculate the scores\n",
    "    score_list.append(score(y_test[test_data_indices], preds))\n",
    "\n",
    "# Find the average time taken for inference by sklearn\n",
    "t_predict_sklearn = np.mean(np.array(inference_time_list))\n",
    "\n",
    "# Find the average inference score of sklearn\n",
    "score_sklearn = np.mean(np.array(score_list))\n",
    "\n",
    "# Show the scores\n",
    "print(\"Inference time (sklearn): %6.2f milliseconds\" % (1000*t_predict_sklearn))\n",
    "print(\"Accuracy score (sklearn): %.4f\" % (score_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:27.375081Z",
     "iopub.status.busy": "2022-04-04T14:47:27.374715Z",
     "iopub.status.idle": "2022-04-04T14:47:29.066228Z",
     "shell.execute_reply": "2022-04-04T14:47:29.066521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Snap ML Random Forest Classifier model\n",
    "snapml_model = SnapRandomForestClassifier()\n",
    "\n",
    "# Import the scikit-learn model into Snap ML\n",
    "# Inferences would now be performed using the Snap ML framework\n",
    "# We can take advantage of the IBM z16's AI acceleration capabilities by passing `tree_format=\"zdnn_tensors\"`\n",
    "snapml_model.import_model(\"model.pmml\", \"pmml\")\n",
    "\n",
    "# Set the number of CPU threads used at inference time\n",
    "snapml_model.set_params(n_jobs=4)\n",
    "\n",
    "# As before, we seed the numpy's random number generator\n",
    "np.random.seed(1000)\n",
    "\n",
    "# Set the size of dataset to be used for testing\n",
    "test_data_size = 128\n",
    "\n",
    "inference_time_list = []\n",
    "score_list = []\n",
    "\n",
    "# Do inferences on 100 batches of transactions, now using Snap ML instead of sklearn\n",
    "# Please see previous cell for detailed info of each step\n",
    "for batch_index in range(100):\n",
    "    test_data_indices = np.random.choice(X_test.shape[0], test_data_size)\n",
    "\n",
    "    t0 = time.time()\n",
    "    preds = snapml_model.predict(X_test[test_data_indices])\n",
    "    t_predict_snapml = time.time() - t0\n",
    "    \n",
    "    inference_time_list.append(t_predict_snapml)\n",
    "    score_list.append(score(y_test[test_data_indices], preds))\n",
    "\n",
    "# Find the average time taken and inference scores\n",
    "t_predict_snapml = np.mean(np.array(inference_time_list))\n",
    "score_snapml = np.mean(np.array(score_list))\n",
    "print(\"Inference time (snapml): %6.2f milliseconds\" % (1000*t_predict_snapml))\n",
    "print(\"Accuracy score (snapml): %.4f\" % (score_snapml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:29.070056Z",
     "iopub.status.busy": "2022-04-04T14:47:29.069701Z",
     "iopub.status.idle": "2022-04-04T14:47:29.071730Z",
     "shell.execute_reply": "2022-04-04T14:47:29.071428Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the speed difference between sklearn and Snap ML\n",
    "speed_up = t_predict_sklearn/t_predict_snapml\n",
    "\n",
    "# Get the score difference between sklearn and Snap ML\n",
    "score_diff = (score_snapml - score_sklearn)/score_sklearn\n",
    "\n",
    "# Show the results\n",
    "print(\"Snap ML vs Scikit-Learn Inference Speed-up: %.1f x\" % (speed_up))\n",
    "print(\"Relative diff. in score: %.4f\" % (score_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "Performance results always depend on the hardware and software environment. \n",
    "\n",
    "Information regarding the environment that was used to run this notebook are provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T14:47:29.074494Z",
     "iopub.status.busy": "2022-04-04T14:47:29.073143Z",
     "iopub.status.idle": "2022-04-04T14:47:29.883979Z",
     "shell.execute_reply": "2022-04-04T14:47:29.884271Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "environment = utils.get_environment()\n",
    "for k,v in environment.items():\n",
    "    print(\"%15s: %s\" % (k, v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
